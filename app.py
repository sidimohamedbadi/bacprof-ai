import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import os
from typing import List, Dict

st.set_page_config(page_title="BacProf-AI", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ BacProf-AI â€“ Ton vrai prof IA pour le Bac Terminale")

# ==================== CONFIGURATION ====================
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

api_key = st.text_input(
    "ğŸ”‘ Colle ta clÃ© API Gemini (gratuite)",
    value=st.session_state.api_key,
    type="password",
    help="Va sur https://aistudio.google.com/app/apikey â†’ Create API key"
)

if api_key:
    st.session_state.api_key = api_key
    genai.configure(api_key=api_key)

# ModÃ¨le embeddings (trÃ¨s rapide)
@st.cache_resource
def get_embedding_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

embedder = get_embedding_model()

# ==================== STOCKAGE SESSION ====================
if "documents" not in st.session_state:
    st.session_state.documents = []
if "faiss_index" not in st.session_state:
    st.session_state.faiss_index = None
if "chunks" not in st.session_state:
    st.session_state.chunks = []
if "mastery" not in st.session_state:  # Vision 360Â°
    st.session_state.mastery = {}  # {"compÃ©tence": {"color": "vert", "errors": 0}}
if "history" not in st.session_state:
    st.session_state.history = []

# ==================== FONCTIONS ====================
def extract_text_from_pdfs(files):
    text = ""
    for file in files:
        reader = PdfReader(file)
        for page in reader.pages:
            text += page.extract_text() + "\n\n"
    return text

def split_text(text: str) -> List[str]:
    # DÃ©coupage intelligent
    splitter = text.split("\n\n")
    chunks = [c.strip() for c in splitter if len(c.strip()) > 50]
    return chunks

def build_faiss_index(chunks):
    embeddings = embedder.encode(chunks, show_progress_bar=False)
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings.astype('float32'))
    return index, embeddings

def retrieve_context(query: str, k=5) -> str:
    if st.session_state.faiss_index is None:
        return "Aucun cours chargÃ© pour l'instant."
    query_emb = embedder.encode([query])
    D, I = st.session_state.faiss_index.search(query_emb.astype('float32'), k)
    context = "\n\n".join([st.session_state.chunks[i] for i in I[0]])
    return context

# Prompt systÃ¨me ultra-puissant (le "vrai prof agrÃ©gÃ©")
SYSTEM_PROMPT = """Tu es un professeur agrÃ©gÃ© de Terminale qui prÃ©pare le Bac depuis 20 ans.
Tu suis EXACTEMENT la mÃ©thodologie des cours et des annales corrigÃ©es que l'Ã©lÃ¨ve a uploadÃ©es.
RÃ¨gles strictes :
- Utilise uniquement les mÃ©thodes prÃ©sentes dans les documents fournis.
- RÃ©ponds toujours avec les mÃªmes Ã©tapes numÃ©rotÃ©es, les mÃªmes notations et phrases que dans les corrigÃ©s officiels.
- Quand tu crÃ©es un exercice, il doit Ãªtre 100% neuf mais dans le mÃªme style BAC.
- Analyse les erreurs de l'Ã©lÃ¨ve et dis-lui prÃ©cisÃ©ment quel point il n'a pas maÃ®trisÃ©.
- Utilise le contexte ci-dessous pour rÃ©pondre.

Contexte des cours et annales :
{context}
"""

def ask_prof(prompt: str, exercice_mode=False):
    if not api_key:
        return "âŒ Mets ta clÃ© Gemini d'abord."
    
    context = retrieve_context(prompt)
    full_prompt = SYSTEM_PROMPT.format(context=context) + "\n\nQuestion de l'Ã©lÃ¨ve : " + prompt
    
    model = genai.GenerativeModel('gemini-1.5-flash')
    response = model.generate_content(full_prompt)
    return response.text

# ==================== INTERFACE ====================
tab1, tab2, tab3 = st.tabs(["ğŸ“š Charger mes cours & annales", "ğŸ’¬ Chat avec mon prof IA", "ğŸ“Š Ma vision 360Â°"])

with tab1:
    st.subheader("Charge tous tes PDFs (cours + annales corrigÃ©es)")
    uploaded_files = st.file_uploader("SÃ©lectionne tous tes fichiers PDF", type="pdf", accept_multiple_files=True)
    
    if st.button("ğŸš€ Indexer tout le programme", type="primary"):
        if uploaded_files:
            with st.spinner("Lecture des PDFs + crÃ©ation de la base de connaissance..."):
                full_text = extract_text_from_pdfs(uploaded_files)
                st.session_state.chunks = split_text(full_text)
                st.session_state.faiss_index, _ = build_faiss_index(st.session_state.chunks)
                st.success(f"âœ… {len(st.session_state.chunks)} morceaux de cours indexÃ©s ! Tu peux maintenant discuter avec ton prof.")
        else:
            st.error("Charge au moins un PDF")

with tab2:
    st.subheader("Pose n'importe quelle question ou demande un exercice")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("âœ¨ GÃ©nÃ¨re un exercice sur..."):
            sujet = st.text_input("Sur quel chapitre / notion ?", "dÃ©rivÃ©es fonctions", key="sujet")
            if sujet:
                response = ask_prof(f"GÃ©nÃ¨re un exercice complet NEUF sur : {sujet}. Donne l'Ã©noncÃ© puis la correction dÃ©taillÃ©e avec la mÃ©thodologie exacte du cours.", exercice_mode=True)
                st.write(response)
    
    with col2:
        if st.button("ğŸ“ Analyse mon erreur"):
            erreur = st.text_area("Colle ici ta rÃ©ponse ou ton erreur", height=100)
            if erreur:
                response = ask_prof(f"Analyse cette rÃ©ponse de l'Ã©lÃ¨ve et dis-moi prÃ©cisÃ©ment les lacunes et comment corriger avec la mÃ©thode du cours : {erreur}")
                st.write(response)
                # Mise Ã  jour couleurs erreurs (prototype simple)
                st.session_state.mastery["Exemple compÃ©tence"] = {"color": "orange", "errors": 2}

    # Chat classique
    user_input = st.chat_input("Demande un exercice, une explication, etc.")
    if user_input:
        st.session_state.history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        
        with st.chat_message("assistant"):
            with st.spinner("Ton prof rÃ©flÃ©chit..."):
                answer = ask_prof(user_input)
                st.markdown(answer)
        
        st.session_state.history.append({"role": "assistant", "content": answer})

with tab3:
    st.subheader("ğŸ“Š Ma vision 360Â° â€“ Ce que je maÃ®trise vraiment")
    if not st.session_state.mastery:
        st.info("Commence Ã  faire des exercices pour voir les couleurs apparaÃ®tre")
    else:
        for comp, data in st.session_state.mastery.items():
            color = data["color"]
            emoji = "ğŸŸ¢" if color == "vert" else "ğŸŸ " if color == "orange" else "ğŸ”´"
            st.write(f"{emoji} **{comp}** â€” {data['errors']} erreurs dÃ©tectÃ©es")

st.caption("BacProf-AI Prototype v1 â€“ CrÃ©Ã© avec â¤ï¸ pour les Terminales 2026")
